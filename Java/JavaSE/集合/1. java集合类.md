## 集合接口Collection
Java 集合，也叫作容器，主要是由两大接口派生而来：一个是 `Collection`接口，主要用于存放单一元素；另一个是 `Map` 接口，主要用于存放键值对。对于`Collection` 接口，下面又有三个主要的子接口：`List`、`Set` 、 `Queue`。

- **List**：ArrayList、Vector、LinkedList
- **Set**：HashSet、LinkedHashSet、TreeSet
- **Queue**：PriorityQueue、DelayQueue、ArrayDeque
- **Map**：HashMap、LinkedHashMap、Hashtable、TreeMap
## List
### ArrayList
> [ArrayList 源码分析 | JavaGuide](https://javaguide.cn/java/collection/arraylist-source-code.html#arraylist-%E7%AE%80%E4%BB%8B)

- 内部基于动态数组实现
- 线程不安全
- `ArrayList` 底层使用的是 **`Object` 数组**
#### 扩容机制
- 创建一个空列表容量为0，创建一个带参的（x），容量为x
- 在add时，尽在列表为空的情况下，容量设置为10；如果容量小于元素数量，也要扩容`grow`
- `grow`方法功能是：新容量更新为旧容量的1.5倍，`size = size + (size>>1)`
- size最大容量为`Integer.MAX_VALUE`，判断size溢出通过 int 类型size数字是否小于零（计算机组成原理）
> `length`：数组长度
> `length()`：字符串长度
> `size()`：泛型集合长度

#### `System.arraycopy()` 和 `Arrays.copyOf()`方法
- `copyOf()`内部实际调用了 `System.arraycopy()` 方法，创建一个新数组来接收
- `arraycopy()` 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 `copyOf()` 是系统自动在内部新建一个数组，并返回该数组。

**`System.arraycopy()`**

```java
    /**
    *   复制数组
    * @param src 源数组
    * @param srcPos 源数组中的起始位置
    * @param dest 目标数组
    * @param destPos 目标数组中的起始位置
    * @param length 要复制的数组元素的数量
    */
    public static native void arraycopy(Object src,  int  srcPos,
                                        Object dest, int destPos,
                                        int length);
```

**样例：**
```
/*
dest <- src
int[] src = {1,2,3,0,0,0,0}
int[] dest = {0,0,0,1,2,3,0}
arraycopy(src,0,dest,0,3)
int[] src = {1,2,3,0,0,0,0}
int[] dest = {1,2,3,1,2,3,0}
*/
```

**`Arrays.copyOf()`**
```java
    public static int[] copyOf(int[] original, int newLength) {
      // 申请一个新的数组
        int[] copy = new int[newLength];
  // 调用System.arraycopy,将源数组中的数据进行拷贝,并返回新的数组
        System.arraycopy(original, 0, copy, 0,
                         Math.min(original.length, newLength));
        return copy;
    }
```

**样例：**
```
/*
dest <- src
int[] src = {1,2,3,0,0,0,0}
int[] dest = {0,0,0,1,2,3,0}
dest = Arrays.copyOf(src,10);
int[] src = {1,2,3,0,0,0,0}
int[] dest = {1, 2, 3, 0, 0, 0, 0, 0, 0, 0}
dest = Arrays.copyOf(src,2);
int[] dest = {1, 2}
*/
```
#### ensureCapacity方法
直接增加容量，至少是N，这样可以减少在add元素时扩容，增加运行效率
### Vector
线程安全的list，但是锁粒度很大，每次都锁整张list
### LinkedList
双向链表
### CopyOnWriteArrayList
#### Copy-On-Write 的思想是什么？
对于大部分业务场景来说，读取操作往往是远大于写入操作的。由于读取操作不会对原有数据进行修改，因此，对于每次读取都进行加锁其实是一种资源浪费。允许多个线程同时访问 `List` 的内部数据，毕竟对于读取操作来说是安全的。

这`ReentrantReadWriteLock` 读写锁的设计思想非常类似，即读读不互斥、读写互斥、写写互斥（只有读读不互斥）。`CopyOnWriteArrayList` 更进一步地实现了这一思想。

为了将读操作性能发挥到极致，`CopyOnWriteArrayList` 中的读取操作是完全无需加锁的。更加厉害的是，写入操作也不会阻塞读取操作，只有写写才会互斥。这样一来，读操作的性能就可以大幅度提升。

核心在于其采用了 **写时复制（Copy-On-Write）** 的策略

#### 缺点
- 内存占用：每次写操作都需要复制一份原始数据，会占用额外的内存空间，在数据量比较大的情况下，可能会导致内存资源不足。
- 写操作开销：每一次写操作都需要复制一份原始数据，然后再进行修改和替换，所以写操作的开销相对较大，在写入比较频繁的场景下，性能可能会受到影响。
- 数据一致性问题：修改操作不会立即反映到最终结果中，还需要等待复制完成，这可能会导致一定的数据一致性问题。

## Map
### HashMap 
1. 拉链法：数组加链表
2. 扩容：2的幂次方扩容
3. hash冲突：拉链法优化，节点上链表加红黑树
#### 拉链法
- `HashMap` 底层是 **数组和链表** 结合在一起使用也就是 **链表散列**
- HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度，**这样做能确保hash值一定小于等于n-1**）
- 如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。
- 当链表长度大于阈值（默认为 8）（**将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树**）时，将链表转化为红黑树，以减少搜索时间。
#### 负载因子 loadFactor 

loadFactor 负载因子是控制**数组存放数据的疏密程度**，loadFactor 越趋近于 1，那么 数组中存放的数据(entry)也就越多，也就越密，也就是会让链表的长度增加，loadFactor 越小，也就是趋近于 0，数组中存放的数据(entry)也就越少，也就越稀疏。

**loadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值**。

给定的默认容量为 16，负载因子为 0.75。
#### 构造方法
```java
	// 默认构造方法，空map
	public HashMap(){}
	// 用另一个Map构造
	public HashMap(Map<? extends K, ? extends V> m){}
	// 指定“容量大小”的构造函数
	public HashMap(int initialCapacity){}
	// 指定“容量大小”和“负载因子”的构造函数
	public HashMap(int initialCapacity, float loadFactor) {}
```
> **注意：** 指定“容量大小”的并不准确，即使指定了初始化容量 initialCapacity ，也只是通过 tableSizeFor 将其扩容到与 **initialCapacity 最接近的 2 的幂次方大小**

**putMapEntries 方法：** 第三和第四个构造方法中有用到，主要用来判断新增加的容量是否需要扩容，需要扩容到多少

> `tableSizeFor`HashMap容量怎么计算得到的到与 **initialCapacity 最接近的 2 的幂次方大小**?

如下是相关源码，功能是得到**大于等于cap的最近的 2 的幂次值**
```java
	static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n >>> 1;   // >>>代表无符号右移
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
```
简单理解：
- 假设`n=cap-1`按位中至少有一个1，那么`n |= n >>> 1`就会得到，这个位右边一位也会变为1，必然存在连续的两个为1的位
- 以此类推，`n`每次已有的，连续的 1 将会被翻倍，最后至少会有 31 个连续的 1 ，而 int 类型的数字正好只有31位（一位符号位），所以效果就是把 n 中所有位都变为 1 。但是，**如果n=0除外**
- 最后再给n+1，就得到了**大于等于cap的最近的 2 的幂次值**

> 为什么要**2的幂次方的容量**

1. **哈希算法的实现基础**
    - HashMap 使用取模运算来确定元素在哈希表中的存储位置，即`index = hash(key) % n`（其中`n`是哈希表的容量）。在计算机中，取模运算`a % b`（当`b`为 2 的幂次时）可以等价转换为`a & (b - 1)`。这种位运算比一般的取模运算速度更快，能够提高哈希操作的效率。
    - 例如，当哈希表容量`n = 16`（2 的 4 次方）时，`hash(key) % 16`等同于`hash(key) & 15`（16 - 1 = 15）。
2. **保证哈希函数的均匀分布**
    - 为了使元素能够均匀地分布在哈希表中，避免过多的哈希冲突，哈希表的容量最好是 2 的幂次。当容量是 2 的幂次时，通过`hash(key) & (n - 1)`计算出来的索引值能够在`0`到`n - 1`的范围内均匀分布。
    - 如果哈希表容量不是 2 的幂次，例如容量为 15，`hash(key) % 15`对应的二进制操作会变得复杂，而且可能导致哈希值在哈希表中的分布不均匀，增加哈希冲突的概率，进而影响 HashMap 的性能。
3. **扩容的连贯性**
    - HashMap 在扩容时要保持上述哈希操作的高效性和均匀性。将容量扩容到大于等于当前容量`cap`的最近的 2 的幂次值，能够确保在扩容前后，哈希算法的实现机制保持一致，即仍然可以使用高效的位运算来计算元素的存储位置。
    - 例如，原来哈希表容量为 8，扩容后变为 16（大于等于 8 的最近的 2 的幂次值），无论是在容量为 8 还是 16 时，都可以方便地使用`hash(key) & (n - 1)`来确定元素位置，保证了扩容操作不会破坏哈希算法的连贯性和高效性。

#### put 方法
- 如果定位到的数组位置没有元素 就直接插入。
- 如果定位到的数组位置有元素就和要插入的 key 比较
	- 如果 key 相同就直接覆盖
	- 如果 key 不相同，就判断 p 是否是一个树节点
		- 如果是就调用红黑树的插入操作
		- 如果不是就遍历链表插入(插入的是链表尾部)。
#### get方法
和`put`原理类似
- 先判断数组桶中是否有元素，如果没有返回null
- 如果数组有元素，判断数组桶是否只有一个元素，是就返回
	- 如果有多个元素，判断结构是链表还是红黑树，是链表就遍历查找
	- 如果是红黑树，调用红黑树查找元素的方法
#### resize方法
进行扩容，会伴随着一次重新 hash 分配，并且会遍历 hash 表中所有的元素，是非常耗时的。在编写程序中，要尽量避免 resize。
- **底层的行为都是给 table 赋值一个新的数组**，然后遍历原始的列表，把元素插入到新的数组中
- 每次扩容都是翻倍扩容，但是如果超过了Int.MAX_VALUE，就不再扩容
- 维护两个数，一个是**容量**，一个是**负载因子对应扩容容量**，扩容后都会更新

### ConcurrentHashMap 
#### jdk1.8之前
`ConcurrentHashMap` 对整个桶数组进行了分割分段(`Segment`，分段锁)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。

#### jdk1.8

 `Node` 数组+链表+红黑树的数据结构来实现，并发控制使用 `synchronized` 和 CAS 来操作。

只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。

#### put方法
- 根据 key 计算出 hashcode 。
- 判断是否需要进行初始化。
- 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
- 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容。
- 如果都不满足，则利用 synchronized 锁写入数据。
- 如果数量大于 `TREEIFY_THRESHOLD` 则要执行树化方法，在 `treeifyBin` 中会首先判断当前数组长度 ≥64 时才会将链表转换为红黑树。
#### get方法
1. 根据 hash 值计算位置。
2. 查找到指定位置，如果头节点就是要找的，直接返回它的 value.
3. 如果头节点 hash 值小于 0 ，说明正在扩容或者是红黑树，查找之。
4. 如果是链表，遍历查找之。

#### 为什么 key 和 value 不能为 null？
- **二义性问题**：关于value，如果取出后是null，无法判断这个键是否在map中存过
- 单线程下可以容忍歧义，而多线程下无法容忍。

如果一定要用null，可以使用空对象来代替

> **保证 `ConcurrentHashMap` 复合操作的原子性？**

1. `ConcurrentHashMap`提供了一些原子性的复合操作，如 `putIfAbsent`、`compute`、`computeIfAbsent` 、`computeIfPresent`、`merge`

> 为什么不给`ConcurrentHashMap`增加锁等并发控制？

违背了`ConcurrentHashMap`设计的初衷，反而增大了耗时，如果这么做了可以直接使用HashMap
### TreeMap
`TreeMap` 主要多了对集合中的元素根据键排序的能力以及对集合内元素的搜索的能力。

TreeMap则是基于红黑树的一种提供顺序访问的Map，和HashMap不同，它的get、put、remove之类操作都是O（logN）的时间复杂度，具体顺序可以由指定的Comparator来决定，或者根据键的自然顺序来判断。
### HashTable
- 线程安全（但是整个表是同一把锁，非常垃圾）
- Hashtable 不允许有 null 键和 null 值