## 1. 确定问题存在及时间范围
- **监控工具确认问题**
- **应用日志分析**
## 2. 初步排查服务器资源情况
### 查看服务器负载
 **`top`命令**（在 Linux 系统中）查看服务器的整体负载情况，包括 CPU 使用率、内存使用率、负载均衡指标（`load average`）等。

确定是否存在其他进程也在大量占用服务器资源，如果是，则需要进一步排查是资源竞争还是其他进程异常导致的问题。

### 内存使用情况排查
**`free -m`命令**查看服务器的内存使用情况，了解是否存在内存不足导致的频繁 GC（垃圾回收），进而引起 CPU 飙升。

如果`free`列的值较低，且`buffers/cache`列的值较高，可能需要考虑优化内存配置或查找内存泄漏问题。

## 3. 分析 JVM 进程状态
### 获取 JVM 进程详细信息
**`jps`命令**（JDK 自带工具）列出当前运行的 Java 进程，找到目标 JVM 进程的 PID。

```shell
> jps
4480
11156 Jps
21692 RemoteMavenServer36
```

**`jstat -gcutil <PID>`命令**查看 JVM 的垃圾回收情况，重点关注`YGC`（年轻代垃圾回收次数）、`YGCT`（年轻代垃圾回收时间）、`FGC`（老年代垃圾回收次数）和`FGCT`（老年代垃圾回收时间）等指标。

```shell
> jstat -gcutil 4480
  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT
  0.00  95.53  11.54  83.67  98.78  95.92     55    0.329     0    0.000    0.329
```

如果`YGC`和`YGCT`频繁增加，可能是年轻代内存分配不合理或存在大量短生命周期的对象导致频繁回收。如果`FGC`和`FGCT`异常增加，可能是老年代内存不足或存在内存泄漏导致对象无法被回收，从而引发频繁的 Full GC，消耗大量 CPU 资源。

### 查看线程状态
**`jstack <PID>`命令**获取 JVM 进程的线程栈信息。在输出结果中，查找处于 **`RUNNABLE`状态** 且占用 CPU 时间较长的线程。这些线程可能是导致 CPU 飙升的罪魁祸首。

```shell
jstack 4480 | grep -i RUNNABLE
   java.lang.Thread.State: RUNNABLE
"Service Thread" #6 daemon prio=9 os_prio=0 cpu=62.50ms elapsed=784.24s tid=0x0000026548c08c10 nid=0x536c runnable  [0x0000000000000000]
   java.lang.Thread.State: RUNNABLE
"Monitor Deflation Thread" #7 daemon prio=9 os_prio=0 cpu=0.00ms elapsed=784.24s tid=0x0000026548c0b4e0 nid=0x5374 runnable  [0x0000000000000000]
# ...省略
```

对于高 CPU 占用的线程，可以查看其栈帧信息，分析其正在执行的方法。

通常，通过查看栈帧中的类名、方法名和行号，可以初步判断是业务逻辑代码、第三方库代码还是 JVM 内部代码导致的问题。

例如，如果栈帧中显示是业务逻辑中的某个复杂计算方法，那么可能需要对该方法进行优化。

## 4. 小结
首先，通过**日志和监控工具**来判断问题的发生时间和场景

然后，排查**服务器内存和CPU使用率**，分辨可能出现问题的原因

再然后，使用JVM相关的命令，使用`jps`列出所有的java进程
- 排查java进程的运行状态 ，使用`jstat`命令检查 **JVM的新生代和老年代的回收次数和回收时间** ；
- 使用`jstack`命令查看**java线程栈信息**，查找处于 **`RUNNABLE`状态** 且占用 CPU 时间较长的线程。

最后，定位问题要解决问题，一般有下面两种：
- 如果是内存分配问题，可以调整 JVM 的内存参数（如`-Xmx`、`-Xms`、`-Xmn`等）。
- 如果是业务逻辑代码问题，对性能瓶颈代码进行重构或优化算法。